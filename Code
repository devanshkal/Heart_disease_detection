!pip install tensorflow

import pandas as pd
import numpy as np
import csv
import io
import os
import zipfile

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_validate,  cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, auc, RocCurveDisplay
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Flatten, Concatenate, Dense, Input, Add, Reshape, Attention, Multiply, Flatten, Dropout, BatchNormalization, MultiHeadAttention, LayerNormalization
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam, schedules
from tensorflow.keras.optimizers.schedules import ExponentialDecay
from tensorflow.keras.regularizers import l2
from sklearn.metrics import accuracy_score
import time
from tensorflow.keras.activations import softmax
from time import time
from sklearn.metrics import roc_auc_score, make_scorer
import warnings

data = pd.read_csv('/content/heart (1).csv')
data

plt.figure(figsize=(15, 15))

num_features = len(data.select_dtypes(include='number').columns)
num_cols = 3
num_rows = (num_features + num_cols - 1) // num_cols

for i, feature in enumerate(data.select_dtypes(include='number').columns):
    plt.subplot(num_rows, num_cols, i+1)
    sns.histplot(data=data, x=feature, bins=30, kde=True)
    plt.title(f'{feature} ')
plt.tight_layout()

#CORRELATION HEAT MAP
plt.figure(figsize=(15,8))
numeric_data = data.select_dtypes(include=np.number)
sns.heatmap(numeric_data.corr(), annot = True, cmap="Blues")
plt.show()

X = data.drop('target', axis=True)
y = data['target']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

#FEEDFORWARD NEURAL NETWORK
X_train_reshaped = X_train.reshape(-1, X_train.shape[1], 1)
X_test_reshaped = X_test.reshape(-1, X_test.shape[1], 1)

model = Sequential()
model.add(Dense(11,activation='relu',input_dim=13))
model.add(Dense(1,activation='sigmoid'))
model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])

model.summary()

early_stopping = EarlyStopping(monitor='val_loss',patience=10)

history = model.fit(X_train, y_train, epochs=300, validation_data=(X_test, y_test), callbacks=[early_stopping])

X_test_reshaped = X_test_reshaped.reshape(X_test_reshaped.shape[0], -1)

model_pred = (model.predict(X_test_reshaped) > 0.5).astype(int).flatten()
print(classification_report(y_test, model_pred))

# Generate the confusion matrix
conf_matrix = confusion_matrix(y_test, model_pred)

# Plotting the confusion matrix with increased font size
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
            annot_kws={"size": 18})  # Increase font size here
plt.xlabel("Predicted Label", fontsize=12)
plt.ylabel("True Label", fontsize=12)
plt.title("Confusion Matrix", fontsize=14)
plt.show()

plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.show()

plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.show()

Y_pred_prob = model.predict(X_test_reshaped)

fpr, tpr, thresholds = roc_curve(y_test, Y_pred_prob)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # Diagonal line
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

print(f"AUC Score: {roc_auc:.2f}")

#FNN WITH ATTENTION MECHANISM 
input_layer = Input(shape=(X_train.shape[1],))

x = Dense(64, activation='relu')(input_layer)
x = Dropout(0.2)(x)

x = Dense(32, activation='relu')(x)
x = Dropout(0.3)(x)

x = Dense(16, activation='relu')(x)
x = Dropout(0.2)(x)

x = Reshape((-1, 16))(x)

query = key = value = x
x = MultiHeadAttention(num_heads=4, key_dim=16)(query, key, value)
x = LayerNormalization()(x)

output_layer = Dense(1, activation='sigmoid')(x)

model = Model(inputs=input_layer, outputs=output_layer)

model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

early_stopping = EarlyStopping(monitor='val_loss', patience=10)

history = model.fit(X_train_reshaped, y_train, epochs=300, validation_data=(X_test_reshaped, y_test), callbacks=[early_stopping])

model_pred = (model.predict(X_test_reshaped) > 0.5).astype(int).flatten()

print(classification_report(y_test, model_pred))

conf_matrix = confusion_matrix(y_test, model_pred)

plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
            annot_kws={"size": 18})
plt.xlabel("Predicted Label", fontsize=12)
plt.ylabel("True Label", fontsize=12)
plt.title("Confusion Matrix", fontsize=14)
plt.show()

plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.show()

plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.show()

Y_pred_prob = model.predict(X_test)

Y_pred_prob = Y_pred_prob.ravel()

fpr, tpr, thresholds = roc_curve(y_test, Y_pred_prob)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

print(f"AUC Score: {roc_auc:.2f}")
